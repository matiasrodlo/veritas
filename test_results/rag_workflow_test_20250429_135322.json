{
  "device": "mps",
  "model_settings": {
    "embedding_model": "sentence-transformers/all-mpnet-base-v2",
    "generation_model": "mistralai/Mistral-7B-Instruct-v0.3",
    "temperature": 0.7,
    "top_p": 0.95,
    "repetition_penalty": 1.1
  },
  "performance_settings": {
    "embed_batch_size": 32,
    "gen_batch_size": 4,
    "embed_max_length": 1024,
    "gen_max_length": 1024,
    "chunk_size": 512
  },
  "results": {
    "chunking": {
      "fixed": {
        "num_chunks": 1,
        "avg_chunk_size": 236.0,
        "chunks": [
          {
            "text": "Retrieval-Augmented Generation (RAG) Systems RAG is a powerful approach that combines large language models with information retrieval to generate more accurate and factual responses. Here are the key components and concepts: Key Components: 1. Document Retriever: Uses dense or sparse embeddings to find relevant documents 2. Context Processor: Chunks and processes documents for efficient retrieval 3. Generator Model: A large language model that generates responses using retrieved context 4. Vector Store: Database for storing and searching document embeddings Chunking in RAG: Chunking is crucial for several reasons: - Breaks large documents into manageable pieces - Enables more precise retrieval of relevant information - Helps maintain context windows within model limits - Improves search accuracy by focusing on specific segments - Allows for better handling of document structure Best Practices: - Use semantic chunking when possible - Maintain appropriate chunk sizes (typically 256-1024 tokens) - Include overlap between chunks to preserve context - Store metadata with chunks for better retrieval - Implement proper preprocessing and cleaning Benefits of RAG: 1. Reduced hallucination through grounding in documents 2. Improved accuracy and factuality of responses 3. Ability to handle domain-specific knowledge 4. Dynamic knowledge updates without model retraining 5. Better transparency and traceability of information Implementation Considerations: - Choose appropriate embedding models - Optimize chunk size for your use case - Consider using hybrid search (dense + sparse) - Implement proper caching mechanisms - Monitor and evaluate retrieval quality",
            "chunk_index": 0,
            "total_chunks": 1,
            "word_count": 236,
            "strategy": "fixed",
            "doc_id": 0
          }
        ]
      },
      "sentence": {
        "num_chunks": 1,
        "avg_chunk_size": 236.0,
        "chunks": [
          {
            "text": "Retrieval-Augmented Generation (RAG) Systems\n\nRAG is a powerful approach that combines large language models with information retrieval to generate more accurate and factual responses. Here are the key components and concepts:\n\nKey Components:\n1. Document Retriever: Uses dense or sparse embeddings to find relevant documents\n2. Context Processor: Chunks and processes documents for efficient retrieval\n3. Generator Model: A large language model that generates responses using retrieved context\n4. Vector Store: Database for storing and searching document embeddings\n\nChunking in RAG:\nChunking is crucial for several reasons:\n- Breaks large documents into manageable pieces\n- Enables more precise retrieval of relevant information\n- Helps maintain context windows within model limits\n- Improves search accuracy by focusing on specific segments\n- Allows for better handling of document structure\n\nBest Practices:\n- Use semantic chunking when possible\n- Maintain appropriate chunk sizes (typically 256-1024 tokens)\n- Include overlap between chunks to preserve context\n- Store metadata with chunks for better retrieval\n- Implement proper preprocessing and cleaning\n\nBenefits of RAG:\n1. Reduced hallucination through grounding in documents\n2. Improved accuracy and factuality of responses\n3. Ability to handle domain-specific knowledge\n4. Dynamic knowledge updates without model retraining\n5. Better transparency and traceability of information\n\nImplementation Considerations:\n- Choose appropriate embedding models\n- Optimize chunk size for your use case\n- Consider using hybrid search (dense + sparse)\n- Implement proper caching mechanisms\n- Monitor and evaluate retrieval quality",
            "chunk_index": 0,
            "total_chunks": 1,
            "word_count": 236,
            "strategy": "sentence",
            "doc_id": 0
          }
        ]
      },
      "paragraph": {
        "num_chunks": 1,
        "avg_chunk_size": 236.0,
        "chunks": [
          {
            "text": "Retrieval-Augmented Generation (RAG) Systems RAG is a powerful approach that combines large language models with information retrieval to generate more accurate and factual responses. Here are the key components and concepts: Key Components: 1. Document Retriever: Uses dense or sparse embeddings to find relevant documents 2. Context Processor: Chunks and processes documents for efficient retrieval 3. Generator Model: A large language model that generates responses using retrieved context 4. Vector Store: Database for storing and searching document embeddings Chunking in RAG: Chunking is crucial for several reasons: - Breaks large documents into manageable pieces - Enables more precise retrieval of relevant information - Helps maintain context windows within model limits - Improves search accuracy by focusing on specific segments - Allows for better handling of document structure Best Practices: - Use semantic chunking when possible - Maintain appropriate chunk sizes (typically 256-1024 tokens) - Include overlap between chunks to preserve context - Store metadata with chunks for better retrieval - Implement proper preprocessing and cleaning Benefits of RAG: 1. Reduced hallucination through grounding in documents 2. Improved accuracy and factuality of responses 3. Ability to handle domain-specific knowledge 4. Dynamic knowledge updates without model retraining 5. Better transparency and traceability of information Implementation Considerations: - Choose appropriate embedding models - Optimize chunk size for your use case - Consider using hybrid search (dense + sparse) - Implement proper caching mechanisms - Monitor and evaluate retrieval quality",
            "chunk_index": 0,
            "total_chunks": 1,
            "word_count": 236,
            "strategy": "paragraph",
            "doc_id": 0
          }
        ]
      },
      "semantic": {
        "num_chunks": 6,
        "avg_chunk_size": 38.666666666666664,
        "chunks": [
          {
            "text": "RAG is a powerful approach that combines large language models with information retrieval to generate more accurate and factual responses. Here are the key components and concepts:",
            "chunk_index": 0,
            "total_chunks": 6,
            "word_count": 27,
            "strategy": "semantic",
            "doc_id": 0
          },
          {
            "text": "Key Components: 1. Document Retriever: Uses dense or sparse embeddings to find relevant documents 2. Context Processor: Chunks and processes documents for efficient retrieval 3. Generator Model: A large language model that generates responses using retrieved context 4. Vector Store: Database for storing and searching document embeddings",
            "chunk_index": 1,
            "total_chunks": 6,
            "word_count": 47,
            "strategy": "semantic",
            "doc_id": 0
          },
          {
            "text": "Chunking in RAG: Chunking is crucial for several reasons: - Breaks large documents into manageable pieces - Enables more precise retrieval of relevant information - Helps maintain context windows within model limits - Improves search accuracy by focusing on specific segments - Allows for better handling of document structure",
            "chunk_index": 2,
            "total_chunks": 6,
            "word_count": 49,
            "strategy": "semantic",
            "doc_id": 0
          },
          {
            "text": "Best Practices: - Use semantic chunking when possible - Maintain appropriate chunk sizes (typically 256-1024 tokens) - Include overlap between chunks to preserve context - Store metadata with chunks for better retrieval - Implement proper preprocessing and cleaning",
            "chunk_index": 3,
            "total_chunks": 6,
            "word_count": 38,
            "strategy": "semantic",
            "doc_id": 0
          },
          {
            "text": "Benefits of RAG: 1. Reduced hallucination through grounding in documents 2. Improved accuracy and factuality of responses 3. Ability to handle domain-specific knowledge 4. Dynamic knowledge updates without model retraining 5. Better transparency and traceability of information",
            "chunk_index": 4,
            "total_chunks": 6,
            "word_count": 37,
            "strategy": "semantic",
            "doc_id": 0
          },
          {
            "text": "Implementation Considerations: - Choose appropriate embedding models - Optimize chunk size for your use case - Consider using hybrid search (dense + sparse) - Implement proper caching mechanisms - Monitor and evaluate retrieval quality",
            "chunk_index": 5,
            "total_chunks": 6,
            "word_count": 34,
            "strategy": "semantic",
            "doc_id": 0
          }
        ]
      },
      "hybrid": {
        "num_chunks": 1,
        "avg_chunk_size": 236.0,
        "chunks": [
          {
            "text": "Retrieval-Augmented Generation (RAG) Systems RAG is a powerful approach that combines large language models with information retrieval to generate more accurate and factual responses. Here are the key components and concepts: Key Components: 1. Document Retriever: Uses dense or sparse embeddings to find relevant documents 2. Context Processor: Chunks and processes documents for efficient retrieval 3. Generator Model: A large language model that generates responses using retrieved context 4. Vector Store: Database for storing and searching document embeddings Chunking in RAG: Chunking is crucial for several reasons: - Breaks large documents into manageable pieces - Enables more precise retrieval of relevant information - Helps maintain context windows within model limits - Improves search accuracy by focusing on specific segments - Allows for better handling of document structure Best Practices: - Use semantic chunking when possible - Maintain appropriate chunk sizes (typically 256-1024 tokens) - Include overlap between chunks to preserve context - Store metadata with chunks for better retrieval - Implement proper preprocessing and cleaning Benefits of RAG: 1. Reduced hallucination through grounding in documents 2. Improved accuracy and factuality of responses 3. Ability to handle domain-specific knowledge 4. Dynamic knowledge updates without model retraining 5. Better transparency and traceability of information Implementation Considerations: - Choose appropriate embedding models - Optimize chunk size for your use case - Consider using hybrid search (dense + sparse) - Implement proper caching mechanisms - Monitor and evaluate retrieval quality",
            "chunk_index": 0,
            "total_chunks": 1,
            "word_count": 236,
            "strategy": "hybrid",
            "doc_id": 0
          }
        ]
      }
    },
    "embedding": {
      "num_embeddings": 1,
      "embedding_dim": 768,
      "duration": 0.11942625045776367,
      "throughput": 8.373368469385717
    },
    "index": {
      "num_vectors": 1,
      "dimension": 768,
      "duration": 0.01779627799987793
    },
    "retrieval": {
      "What are the key components of a RAG system?": {
        "k=1": {
          "num_results": 1,
          "duration": 0.05405712127685547,
          "scores": [
            0.23859724402427673
          ]
        },
        "k=3": {
          "num_results": 1,
          "duration": 0.010085105895996094,
          "scores": [
            0.23859724402427673
          ]
        },
        "k=5": {
          "num_results": 1,
          "duration": 0.00946807861328125,
          "scores": [
            0.23859724402427673
          ]
        },
        "k=10": {
          "num_results": 1,
          "duration": 0.009334802627563477,
          "scores": [
            0.23859724402427673
          ]
        }
      },
      "Why is chunking important in RAG and what are the best practices?": {
        "k=1": {
          "num_results": 1,
          "duration": 0.058331966400146484,
          "scores": [
            0.36003488302230835
          ]
        },
        "k=3": {
          "num_results": 1,
          "duration": 0.009439945220947266,
          "scores": [
            0.36003488302230835
          ]
        },
        "k=5": {
          "num_results": 1,
          "duration": 0.0090789794921875,
          "scores": [
            0.36003488302230835
          ]
        },
        "k=10": {
          "num_results": 1,
          "duration": 0.009541749954223633,
          "scores": [
            0.36003488302230835
          ]
        }
      },
      "What are the main benefits of using RAG for question answering?": {
        "k=1": {
          "num_results": 1,
          "duration": 0.05384993553161621,
          "scores": [
            0.5049260854721069
          ]
        },
        "k=3": {
          "num_results": 1,
          "duration": 0.0113677978515625,
          "scores": [
            0.5049260854721069
          ]
        },
        "k=5": {
          "num_results": 1,
          "duration": 0.009325742721557617,
          "scores": [
            0.5049260854721069
          ]
        },
        "k=10": {
          "num_results": 1,
          "duration": 0.009024620056152344,
          "scores": [
            0.5049260854721069
          ]
        }
      },
      "What implementation considerations should be taken into account when building a RAG system?": {
        "k=1": {
          "num_results": 1,
          "duration": 0.00896000862121582,
          "scores": [
            0.3483436107635498
          ]
        },
        "k=3": {
          "num_results": 1,
          "duration": 0.008543968200683594,
          "scores": [
            0.3483436107635498
          ]
        },
        "k=5": {
          "num_results": 1,
          "duration": 0.009268999099731445,
          "scores": [
            0.3483436107635498
          ]
        },
        "k=10": {
          "num_results": 1,
          "duration": 0.008899211883544922,
          "scores": [
            0.3483436107635498
          ]
        }
      }
    },
    "generation": {
      "What are the key components of a RAG system?": {
        "duration": 9.241710186004639,
        "response_length": 342
      },
      "Why is chunking important in RAG and what are the best practices?": {
        "duration": 10.28904914855957,
        "response_length": 367
      },
      "What are the main benefits of using RAG for question answering?": {
        "duration": 48.26060914993286,
        "response_length": 470
      },
      "What implementation considerations should be taken into account when building a RAG system?": {
        "duration": 36.1620306968689,
        "response_length": 362
      }
    }
  }
}